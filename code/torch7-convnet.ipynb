{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'nnx'\n",
    "require 'optim'\n",
    "require 'image'\n",
    "require 'dataset-mnist'\n",
    "require 'pl'\n",
    "require 'paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function loadKaggleTrainDataset()\n",
    "    local file = \"data/train.csv\"\n",
    "\n",
    "    local lines = {}\n",
    "    for line in io.lines(file) do\n",
    "        table.insert(lines, line)\n",
    "    end\n",
    "    \n",
    "    local dataset = {}\n",
    "    for idx = 1, #lines do\n",
    "        local pixels = lines[idx]:split(\",\")\n",
    "        local label = torch.Tensor(1):zero()\n",
    "        local image = torch.Tensor(28, 28):zero()\n",
    "\n",
    "        for row = 1, 28 do\n",
    "            for column = 1, 28 do\n",
    "                image[row][column] = tonumber(pixels[(row - 1) * 28 + column + 1])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        label[1] = pixels[1] + 1\n",
    "        table.insert(dataset, {[1] = image, [2] = label})\n",
    "        xlua.progress(idx, #lines)\n",
    "    end\n",
    "\n",
    "    return dataset\n",
    "end\n",
    "\n",
    "function loadKaggleTestDataset()\n",
    "    local file = \"data/test.csv\"\n",
    "    \n",
    "    local lines = {}\n",
    "    for line in io.lines(file) do\n",
    "        table.insert(lines, line)\n",
    "    end\n",
    "    table.remove(lines, 1) -- remove headers\n",
    "\n",
    "    local dataset = {}\n",
    "    for idx = 1, #lines do\n",
    "        local pixels = lines[idx]:split(\",\")\n",
    "        local image = torch.Tensor(28, 28):zero()\n",
    "\n",
    "        for row = 1, 28 do\n",
    "            for column = 1, 28 do\n",
    "                image[row][column] = tonumber(pixels[(row - 1) * 28 + column])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        table.insert(dataset, {[1] = image})\n",
    "        xlua.progress(idx, #lines)\n",
    "    end\n",
    "\n",
    "    return dataset\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Setting Hyperparameters\n",
    "batchSize = 10\n",
    "learningRate = 0.05\n",
    "momentum = 0\n",
    "maxIter = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Fix Seed\n",
    "torch.manualSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Setting worker\n",
    "torch.setnumthreads(2)\n",
    "print('<torch> set nb of threads to ' .. torch.getnumthreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Use Floats, For SGD\n",
    "torch.setdefaulttensortype('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Define model to Train\n",
    "-- On the 10-class Classification Problem\n",
    "-- Geometry : width and height of input images\n",
    "\n",
    "classes = {'0', '1','2','3','4','5','6','7','8','9'}\n",
    "geometry = {28, 28}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Convolutional Network\n",
    "model = nn.Sequential()\n",
    "\n",
    "-- stage 1 : mean suppresion -> filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(1, 32, 5, 5))\n",
    "model:add(nn.Sigmoid())\n",
    "model:add(nn.SpatialMaxPooling(3, 3, 3, 3))\n",
    "\n",
    "-- stage 2 : mean suppresion -> filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(32, 64, 5, 5))\n",
    "model:add(nn.Sigmoid())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "-- stage 3 : standard 2-layer MLP:\n",
    "model:add(nn.Reshape(64*2*2))\n",
    "model:add(nn.Linear(64*2*2, 200))\n",
    "model:add(nn.Sigmoid())\n",
    "model:add(nn.Linear(200, #classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Retrieve parameters and gradients\n",
    "parameters, gradParameters = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('<mnist> using model:')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Loss function : Negative log-likeligood\n",
    "model:add(nn.LogSoftMax())\n",
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbTrainingPatches = 42000\n",
    "nbTestingPatches = 28000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainData = loadKaggleTrainDataset()\n",
    "--trainData:normalizeGlobal(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData = loadKaggleTestDataset()\n",
    "--testData:normalizeGlobal(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion = optim.ConfusionMatrix(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Train function\n",
    "function train(dataset)\n",
    "    -- epoch tracker\n",
    "    epoch = epoch or 1\n",
    "\n",
    "    -- local vars\n",
    "    local time = sys.clock()\n",
    "\n",
    "    -- do one epoch\n",
    "    print('<trainer> on training set:')\n",
    "    print(\"<trainer> online epoch # \" .. epoch .. ' [batchSize = ' .. batchSize .. ']')\n",
    "    for t = 1,nbTrainingPatches,batchSize do\n",
    "        -- create mini batch\n",
    "        local inputs = torch.Tensor(batchSize,1,geometry[1],geometry[2])\n",
    "        local targets = torch.Tensor(batchSize)\n",
    "        local k = 1\n",
    "        for i = t,math.min(t+batchSize-1,nbTrainingPatches) do\n",
    "            -- load new sample\n",
    "            inputs[k] = dataset[i][1]:clone() -- copy data\n",
    "            targets[k] = dataset[i][2]:clone():squeeze() -- copy label\n",
    "            k = k + 1\n",
    "        end\n",
    "\n",
    "        -- create closure to evaluate f(X) and df/dX\n",
    "        local feval = function(x)\n",
    "            -- just in case:\n",
    "            collectgarbage()\n",
    "\n",
    "            -- get new parameters\n",
    "            if x ~= parameters then\n",
    "                parameters:copy(x)\n",
    "            end\n",
    "\n",
    "            -- reset gradients\n",
    "            gradParameters:zero()\n",
    "\n",
    "            -- evaluate function for complete mini batch\n",
    "            local outputs = model:forward(inputs)\n",
    "            local f = criterion:forward(outputs, targets)\n",
    "\n",
    "            -- estimate df/dW\n",
    "            local df_do = criterion:backward(outputs, targets)\n",
    "            model:backward(inputs, df_do)\n",
    "\n",
    "            -- update confusion\n",
    "            for i = 1,batchSize do\n",
    "            confusion:add(outputs[i], targets[i])\n",
    "            end\n",
    "\n",
    "            -- return f and df/dX\n",
    "            return f,gradParameters\n",
    "        end\n",
    "\n",
    "        -- Perform SGD step:\n",
    "        sgdState = sgdState or {\n",
    "            learningRate = learningRate,\n",
    "            momentum = momentum,\n",
    "            learningRateDecay = 5e-7\n",
    "        }\n",
    "        optim.sgd(feval, parameters, sgdState)\n",
    "\n",
    "        -- disp progress\n",
    "        xlua.progress(t, nbTrainingPatches)\n",
    "    end\n",
    "   \n",
    "    -- time taken\n",
    "    time = sys.clock() - time\n",
    "    time = time / nbTrainingPatches\n",
    "    print(\"<trainer> time to learn 1 sample = \" .. (time*1000) .. 'ms')\n",
    "\n",
    "    -- print confusion matrix\n",
    "    print(confusion)\n",
    "    confusion:zero()\n",
    "\n",
    "    -- next epoch\n",
    "    epoch = epoch + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Test function\n",
    "function test(dataset)\n",
    "\n",
    "    os.execute('rm -f submission.csv; touch submission.csv')\n",
    "    results = io.open('submission.csv', \"a\")\n",
    "    results:write('ImageId,Label\\n')\n",
    "    \n",
    "    -- local vars\n",
    "    local time = sys.clock()\n",
    "\n",
    "    -- test over given dataset\n",
    "    print('<trainer> on testing Set:')\n",
    "    for t = 1,nbTestingPatches,batchSize do\n",
    "        -- disp progress\n",
    "        xlua.progress(t, nbTestingPatches)\n",
    "\n",
    "        -- create mini batch\n",
    "        local inputs = torch.Tensor(batchSize,1,geometry[1],geometry[2])\n",
    "        \n",
    "        local k = 1\n",
    "        for i = t,math.min(t+batchSize-1,nbTestingPatches) do\n",
    "            inputs[k] = dataset[i][1]:clone() -- copy data\n",
    "            k = k + 1\n",
    "        end\n",
    "\n",
    "        -- predict\n",
    "        local predicted = model:forward(inputs)\n",
    "\n",
    "        local _, prediction = predicted:max(2)\n",
    "        for i = 1, prediction:size(1) do\n",
    "            results:write('' .. (t - 1 + i) .. ',' .. classes[prediction[i][1]] .. '\\n')\n",
    "        end\n",
    "    end\n",
    "\n",
    "    results:close()\n",
    "\n",
    "    print(confusion)\n",
    "    confusion:zero()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while true do\n",
    "    train(trainData)\n",
    "    test(testData)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Rewrite submission.csv after every epoch.\n",
    "About 50 Epochs are enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
